@inproceedings{9458712,
  author    = {Mei, Yinan and Song, Shaoxu and Fang, Chenguang and Yang, Haifeng and Fang, Jingyun and Long, Jiang},
  booktitle = {2021 IEEE 37th International Conference on Data Engineering (ICDE)},
  title     = {Capturing Semantics for Imputation with Pre-trained Language Models},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {61-72},
  doi       = {10.1109/ICDE51399.2021.00013}
}

@article{SUN2023120201,
  title    = {Deep learning versus conventional methods for missing data imputation: A review and comparative study},
  journal  = {Expert Systems with Applications},
  volume   = {227},
  pages    = {120201},
  year     = {2023},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.120201},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423007030},
  author   = {Yige Sun and Jing Li and Yifan Xu and Tingting Zhang and Xiaofeng Wang},
  keywords = {Missing data imputation, Deep learning, Generative networks, MICE, MissForest},
  abstract = {Deep learning models have been recently proposed in the applications of missing data imputation. In this paper, we review the popular statistical, machine learning, and deep learning approaches, and discuss the advantages and disadvantages of these methods. We conduct a comprehensive numerical study to compare the performance of several widely-used imputation methods for incomplete tabular (structured) data. Specifically, we compare the deep learning methods: generative adversarial imputation networks (GAIN) with onehot encoding, GAIN with embedding, variational auto-encoder (VAE) with onehot encoding, and VAE with embedding versus two conventional methods: multiple imputation by chained equations (MICE) and missForest. Seven real benchmark datasets and three simulated datasets are considered, including various scenarios with different feature types under different levels of sample sizes. The missing data are generated based on different missing ratios and three kinds of missing mechanisms: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). Our experiments show that, for small or moderate sample sizes, the conventional methods establish better robustness and imputation performance than the deep learning methods. GAINs only perform well in the case of MCAR and often fail in the cases of MAR and MNAR. VAEs are easy to fall into mode collapse in all missing mechanisms. We conclude that the conventional methods, MICE and missForest, are preferable for practitioners to deal with missing data imputation for tabular data with a limited sample size (i.e., n<30,000) in real case analyses.}
}

@article{10.1371/journal.pone.0295632,
    doi = {10.1371/journal.pone.0295632},
    author = {Aljrees, Turki},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Improving prediction of cervical cancer using KNN imputer and multi-model ensemble learning},
    year = {2024},
    month = {01},
    volume = {19},
    url = {https://doi.org/10.1371/journal.pone.0295632},
    pages = {1-24},
    abstract = {Cervical cancer is a leading cause of women's mortality, emphasizing the need for early diagnosis and effective treatment. In line with the imperative of early intervention, the automated identification of cervical cancer has emerged as a promising avenue, leveraging machine learning techniques to enhance both the speed and accuracy of diagnosis. However, an inherent challenge in the development of these automated systems is the presence of missing values in the datasets commonly used for cervical cancer detection. Missing data can significantly impact the performance of machine learning models, potentially leading to inaccurate or unreliable results. This study addresses a critical challenge in automated cervical cancer identificationâ€”handling missing data in datasets. The study present a novel approach that combines three machine learning models into a stacked ensemble voting classifier, complemented by the use of a KNN Imputer to manage missing values. The proposed model achieves remarkable results with an accuracy of 0.9941, precision of 0.98, recall of 0.96, and an F1 score of 0.97. This study examines three distinct scenarios: one involving the deletion of missing values, another utilizing KNN imputation, and a third employing PCA for imputing missing values. This research has significant implications for the medical field, offering medical experts a powerful tool for more accurate cervical cancer therapy and enhancing the overall effectiveness of testing procedures. By addressing missing data challenges and achieving high accuracy, this work represents a valuable contribution to cervical cancer detection, ultimately aiming to reduce the impact of this disease on women's health and healthcare systems.},
    number = {1},
}

@article{Jakobsen2017,
  title={When and how should multiple imputation be used for handling missing data in randomised clinical trials - a practical guide with flowcharts},
  author={Jakobsen, Janus Christian and Gluud, Christian and Wetterslev, J{\o}rn and Winkel, Per},
  journal={BMC Medical Research Methodology},
  volume={17},
  number={1},
  pages={162},
  year={2017},
  publisher={BMC},
  doi={10.1186/s12874-017-0442-1},
  url={https://doi.org/10.1186/s12874-017-0442-1},
  issn={1471-2288},
  date={2017/12/06},
  note={ID: Jakobsen2017}
}

@article{Kleinbort2020,
  author = {Ambar Kleinbort},
  title = {Data Imputation: Beyond Mean, Median, and Mode},
  year = {2020},
  url = {https://opendatascience.com/data-imputation-beyond-mean-median-and-mode/},
  urldate = {2024-01-05},
  journal = {Open Data Science}
}

@article {Sterneb2393,
	author = {Jonathan A C Sterne and Ian R White and John B Carlin and Michael Spratt and Patrick Royston and Michael G Kenward and Angela M Wood and James R Carpenter},
	title = {Multiple imputation for missing data in epidemiological and clinical research: potential and pitfalls},
	volume = {338},
	elocation-id = {b2393},
	year = {2009},
	doi = {10.1136/bmj.b2393},
	publisher = {BMJ Publishing Group Ltd},
	issn = {0959-8138},
	URL = {https://www.bmj.com/content/338/bmj.b2393},
	eprint = {https://www.bmj.com/content},
	journal = {BMJ}
}

@article{Khan2020,
  title={SICE: an improved missing data imputation technique},
  author={Khan, Shahidul Islam and Hoque, Abu Sayed Md Latiful},
  journal={Journal of Big Data},
  volume={7},
  number={1},
  pages={37},
  year={2020},
  publisher={Journal of Big Data},
  doi={10.1186/s40537-020-00313-w},
  url={https://doi.org/10.1186/s40537-020-00313-w},
  issn={2196-1115},
  date={2020/06/12},
  note={ID: Khan2020}
}

@article{articleLearnKNN,
author = {Zhang, Shichao and Li, Xuelong and Zong, Ming and Zhu, Xiaofeng and Cheng, Debo},
year = {2017},
month = {01},
pages = {1-19},
title = {Learning k for kNN Classification},
volume = {8},
journal = {ACM Transactions on Intelligent Systems and Technology},
doi = {10.1145/2990508}
}

@inproceedings{inproceedingsKNearest,
author = {Murti, Della and Pujianto, Utomo and Wibawa, Aji and Akbar, Muhammad},
year = {2019},
month = {10},
pages = {83-88},
title = {K-Nearest Neighbor (K-NN) based Missing Data Imputation},
doi = {10.1109/ICSITech46713.2019.8987530},
booktitle = {2019 5th International Conference on Science in Information Technology}
}

@article{Emmanuel2021,
  title={A survey on missing data in machine learning},
  author={Emmanuel, Tlamelo and Maupong, Thabiso and Mpoeleng, Dimane and Semong, Thabo and Mphago, Banyatsang and Tabona, Oteng},
  journal={Journal of Big Data},
  volume={8},
  number={1},
  pages={140},
  year={2021},
  publisher={Journal of Big Data},
  doi={10.1186/s40537-021-00516-9},
  url={https://doi.org/10.1186/s40537-021-00516-9},
  issn={2196-1115},
  date={2021/10/27},
  note={ID: Emmanuel2021}
}

@misc{wang2022deep,
      title={Are deep learning models superior for missing data imputation in large surveys? Evidence from an empirical comparison}, 
      author={Zhenhua Wang and Olanrewaju Akande and Jason Poulos and Fan Li},
      year={2022},
      eprint={2103.09316},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{park2022longterm,
      title={Long-Term Missing Value Imputation for Time Series Data Using Deep Neural Networks}, 
      author={Jangho Park and Juliane Muller and Bhavna Arora and Boris Faybishenko and Gilberto Pastorello and Charuleka Varadharajan and Reetik Sahu and Deborah Agarwal},
      year={2022},
      eprint={2202.12441},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{camino2019improving,
      title={Improving Missing Data Imputation with Deep Generative Models}, 
      author={Ramiro D. Camino and Christian A. Hammerschmidt and Radu State},
      year={2019},
      eprint={1902.10666},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


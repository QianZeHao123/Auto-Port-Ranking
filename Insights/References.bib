@inproceedings{9458712,
  author    = {Mei, Yinan and Song, Shaoxu and Fang, Chenguang and Yang, Haifeng and Fang, Jingyun and Long, Jiang},
  booktitle = {2021 IEEE 37th International Conference on Data Engineering (ICDE)},
  title     = {Capturing Semantics for Imputation with Pre-trained Language Models},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {61-72},
  doi       = {10.1109/ICDE51399.2021.00013}
}

@article{SUN2023120201,
  title    = {Deep learning versus conventional methods for missing data imputation: A review and comparative study},
  journal  = {Expert Systems with Applications},
  volume   = {227},
  pages    = {120201},
  year     = {2023},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2023.120201},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417423007030},
  author   = {Yige Sun and Jing Li and Yifan Xu and Tingting Zhang and Xiaofeng Wang},
  keywords = {Missing data imputation, Deep learning, Generative networks, MICE, MissForest},
  abstract = {Deep learning models have been recently proposed in the applications of missing data imputation. In this paper, we review the popular statistical, machine learning, and deep learning approaches, and discuss the advantages and disadvantages of these methods. We conduct a comprehensive numerical study to compare the performance of several widely-used imputation methods for incomplete tabular (structured) data. Specifically, we compare the deep learning methods: generative adversarial imputation networks (GAIN) with onehot encoding, GAIN with embedding, variational auto-encoder (VAE) with onehot encoding, and VAE with embedding versus two conventional methods: multiple imputation by chained equations (MICE) and missForest. Seven real benchmark datasets and three simulated datasets are considered, including various scenarios with different feature types under different levels of sample sizes. The missing data are generated based on different missing ratios and three kinds of missing mechanisms: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). Our experiments show that, for small or moderate sample sizes, the conventional methods establish better robustness and imputation performance than the deep learning methods. GAINs only perform well in the case of MCAR and often fail in the cases of MAR and MNAR. VAEs are easy to fall into mode collapse in all missing mechanisms. We conclude that the conventional methods, MICE and missForest, are preferable for practitioners to deal with missing data imputation for tabular data with a limited sample size (i.e., n<30,000) in real case analyses.}
}